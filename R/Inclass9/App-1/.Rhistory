#See how predicted ssc compares to actual ssc values
library(ggplot2)
ggplot(data = test, aes(x = ssc_pred, y = ssc)) +
geom_point(color = "red") +
geom_line(aes(x = ssc, y = ssc), color = "blue")
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
final$gp <- runif(dim(final)[1])
test <- subset(final, final$gp <= 0.1)
train <- subset(final, final$gp > 0.1)
train["gp"] <- NULL
test["gp"] <- NULL
attach(train)
attach(test)
#first fit the linear regression with all features
fit <- lm(ssc ~ age + gender + location + ethnicity + coder
+ som1 + som2 + som3 + som4 + som5 + som6 + som7
+ som8 + som9 + som10 + som11 + som12 + som13 + som14)
#Look at the summary of the Linear Regression Model
summary(fit)
#then apply the stepwise procedure
step <- stepAIC(fit, direction = "both")
#look at the coefficients of the stepwise procedure stored in 'step'
step
#get information about dropped features
step$anova
#remove 'step' from the local environment
rm(step)
#remove 'fit' from the local environment
rm(fit)
#And build the model with just the retained variables
fit1 <- lm( ssc ~ age + location + ethnicity + coder + som1 + som2 + som3 +
som4 + som5 + som10 + som11 + som12 + som13 + som14)
#look at the summary
summary(fit1)
#detach the training set from the environment
detach(train)
#remove 'trainSet' from the local environment
rm(train)
#Make predictions using the test set
test$ssc_pred <- predict(fit1, newdata = test)
#remove 'fit1' from the local environment
rm(fit1)
#See how predicted ssc compares to actual ssc values
library(ggplot2)
ggplot(data = test, aes(x = ssc_pred, y = ssc)) +
geom_point(color = "red") +
geom_line(aes(x = ssc, y = ssc), color = "blue")
step
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
final$gp <- runif(dim(final)[1])
test <- subset(final, final$gp <= 0.1)
train <- subset(final, final$gp > 0.1)
train["gp"] <- NULL
test["gp"] <- NULL
attach(train)
attach(test)
#first fit the linear regression with all features
fit <- lm(ssc ~ age + gender + location + ethnicity + coder
+ som1 + som2 + som3 + som4 + som5 + som6 + som7
+ som8 + som9 + som10 + som11 + som12 + som13 + som14)
#Look at the summary of the Linear Regression Model
summary(fit)
#then apply the stepwise procedure
step <- stepAIC(fit, direction = "both")
#remove 'step' from the local environment
rm(step)
#remove 'fit' from the local environment
rm(fit)
#And build the model with just the retained variables
fit1 <- lm( ssc ~ age + location + ethnicity + coder + som1 + som2 + som3 +
som4 + som5 + som10 + som11 + som12 + som13 + som14)
#look at the summary
summary(fit1)
#detach the training set from the environment
detach(train)
#remove 'trainSet' from the local environment
rm(train)
#Make predictions using the test set
test$ssc_pred <- predict(fit1, newdata = test)
#remove 'fit1' from the local environment
rm(fit1)
#See how predicted ssc compares to actual ssc values
library(ggplot2)
ggplot(data = test, aes(x = ssc_pred, y = ssc)) +
geom_point(color = "red") +
geom_line(aes(x = ssc, y = ssc), color = "blue")
#look at the coefficients of the stepwise procedure stored in 'step'
step
#get information about dropped features
step$anova
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
final$gp <- runif(dim(final)[1])
test <- subset(final, final$gp <= 0.1)
train <- subset(final, final$gp > 0.1)
train["gp"] <- NULL
test["gp"] <- NULL
attach(train)
attach(test)
#first fit the linear regression with all features
fit <- lm(ssc ~ age + gender + location + ethnicity + coder
+ som1 + som2 + som3 + som4 + som5 + som6 + som7
+ som8 + som9 + som10 + som11 + som12 + som13 + som14)
#Look at the summary of the Linear Regression Model
summary(fit)
#then apply the stepwise procedure
step <- stepAIC(fit, direction = "both")
#look at the coefficients of the stepwise procedure stored in 'step'
step
#get information about dropped features
step$anova
#remove 'step' from the local environment
rm(step)
#remove 'fit' from the local environment
rm(fit)
#And build the model with just the retained variables
fit1 <- lm( ssc ~ age + location + ethnicity + coder + som1 + som2 + som3 +
som4 + som5 + som10 + som11 + som12 + som13 + som14)
#look at the summary
summary(fit1)
#detach the training set from the environment
detach(train)
#remove 'trainSet' from the local environment
rm(train)
#Make predictions using the test set
test$ssc_pred <- predict(fit1, newdata = test)
#remove 'fit1' from the local environment
rm(fit1)
#See how predicted ssc compares to actual ssc values
library(ggplot2)
ggplot(data = test, aes(x = ssc_pred, y = ssc)) +
geom_point(color = "red") +
geom_line(aes(x = ssc, y = ssc), color = "blue")
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
final$gp <- runif(dim(final)[1])
test <- subset(final, final$gp <= 0.1)
train <- subset(final, final$gp > 0.1)
train["gp"] <- NULL
test["gp"] <- NULL
attach(train)
attach(test)
#first fit the linear regression with all features
fit <- lm(ssc ~ age + gender + location + ethnicity + coder
+ som1 + som2 + som3 + som4 + som5 + som6 + som7
+ som8 + som9 + som10 + som11 + som12 + som13 + som14)
#Look at the summary of the Linear Regression Model
summary(fit)
#then apply the stepwise procedure
step <- stepAIC(fit, direction = "both")
#look at the coefficients of the stepwise procedure stored in 'step'
step
#get information about dropped features
step$anova
#remove 'step' from the local environment
rm(step)
#remove 'fit' from the local environment
rm(fit)
#And build the model with just the retained variables
fit1 <- lm( ssc ~ age + location + ethnicity + coder + som1 + som2 + som3 +
som4 + som5 + som10 + som11 + som12 + som13 + som14)
#look at the summary
summary(fit1)
#detach the training set from the environment
detach(train)
#remove 'trainSet' from the local environment
rm(train)
#Make predictions using the test set
test$ssc_pred <- predict(fit1, newdata = test)
#remove 'fit1' from the local environment
rm(fit1)
#See how predicted ssc compares to actual ssc values
library(ggplot2)
ggplot(data = test, aes(x = ssc_pred, y = ssc)) +
geom_point(color = "red") +
geom_line(aes(x = ssc, y = ssc), color = "blue")
step$anova
step <- stepAIC(fit, direction = "both")
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
final$gp <- runif(dim(final)[1])
test <- subset(final, final$gp <= 0.1)
train <- subset(final, final$gp > 0.1)
train["gp"] <- NULL
test["gp"] <- NULL
attach(train)
attach(test)
#first fit the linear regression with all features
fit <- lm(ssc ~ age + gender + location + ethnicity + coder
+ som1 + som2 + som3 + som4 + som5 + som6 + som7
+ som8 + som9 + som10 + som11 + som12 + som13 + som14)
#Look at the summary of the Linear Regression Model
summary(fit)
#then apply the stepwise procedure
step <- stepAIC(fit, direction = "both")
#look at the coefficients of the stepwise procedure stored in 'step'
step
#get information about dropped features
step$anova
# Load libraries, set wd, and load/attach data
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
# Create/attach training and test subset as demonstrated in text
final$gp <- runif(dim(final)[1])
test <- subset(final, final$gp <= 0.1)
train <- subset(final, final$gp > 0.1)
attach(train)
attach(test)
# Remove columns used for creating subsets
train["gp"] <- NULL
test["gp"] <- NULL
# Fit linear regression with all features
fit <- lm(ssc ~ age + gender + location + ethnicity + coder + som1 + som2 + som3 + som4
+ som5 + som6 + som7 + som8 + som9 + som10 + som11 + som12 + som13 + som14)
summary(fit)
step <- stepAIC(fit, direction = "both")
step
step$anova
rm(step)
rm(fit)
# Build model with only retained variables
fit1 <- lm( ssc ~ age + location + ethnicity + coder + som1 + som2 + som3 +
som4 + som5 + som10 + som11 + som12 + som13 + som14)
summary(fit1)
# Remove training set (no longer needed)
detach(train)
rm(train)
# Now predict using the test set
test$ssc_pred <- predict(fit1, newdata = test)
rm(fit1)
#See how predicted ssc compares to actual ssc values
library(ggplot2)
ggplot(data = test, aes(x = ssc_pred, y = ssc)) +
geom_point(color = "red") +
geom_line(aes(x = ssc, y = ssc), color = "blue")
# Load libraries, set wd, and load/attach data
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
# Create/attach training and test subset as demonstrated in text
final$gp <- runif(dim(final)[1])
train <- subset(final, final$gp > 0.1)
attach(test)
# Remove columns used for creating subsets
test["gp"] <- NULL
# Fit linear regression with all features
+ som5 + som6 + som7 + som8 + som9 + som10 + som11 + som12 + som13 + som14)
summary(fit)
step
step$anova
rm(fit)
# Build model with only retained variables
som4 + som5 + som10 + som11 + som12 + som13 + som14)
# Remove training set (no longer needed)
detach(train)
rm(train)
# Now predict using the test set
test$ssc_pred <- predict(fit1, newdata = test)
rm(fit1)
#See how predicted ssc compares to actual ssc values
ggplot(data = test, aes(x = ssc_pred, y = ssc)) +
geom_point(color = "red") +
step <- stepAIC(fit, direction = "both")
fit <- lm(ssc ~ age + gender + location + ethnicity + coder + som1 + som2 + som3 + som4
attach(train)
library(ggplot2)
rm(step)
train["gp"] <- NULL
summary(fit1)
geom_line(aes(x = ssc, y = ssc), color = "blue")
test <- subset(final, final$gp <= 0.1)
fit1 <- lm( ssc ~ age + location + ethnicity + coder + som1 + som2 + som3 +
som4 + som5 + som10 + som11 + som12 + som13 + som14)
summary(fit1)
# Remove training set (no longer needed)
detach(train)
rm(train)
# Load libraries, set wd, and load/attach data
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
# Create/attach training and test subset as demonstrated in text
final$gp <- runif(dim(final)[1])
test <- subset(final, final$gp <= 0.1)
train <- subset(final, final$gp > 0.1)
attach(train)
attach(test)
# Remove columns used for creating subsets
train["gp"] <- NULL
test["gp"] <- NULL
# Fit linear regression with all features
fit <- lm(ssc ~ age + gender + location + ethnicity + coder + som1 + som2 + som3 + som4
+ som5 + som6 + som7 + som8 + som9 + som10 + som11 + som12 + som13 + som14)
summary(fit)
step <- stepAIC(fit, direction = "both")
step
step$anova
rm(step)
rm(fit)
# Build model with only retained variables
fit1 <- lm( ssc ~ age + location + ethnicity + coder + som1 + som2 + som3 +
som4 + som5 + som10 + som11 + som12 + som13 + som14)
summary(fit1)
# Remove training set (no longer needed)
detach(train)
rm(train)
# Now predict using the test set
test$ssc_pred <- predict(fit1, newdata = test)
rm(fit1)
#See how predicted ssc compares to actual ssc values
library(ggplot2)
ggplot(data = test, aes(x = ssc_pred, y = ssc)) +
geom_point(color = "red") +
geom_line(aes(x = ssc, y = ssc), color = "blue")
# Load libraries, set wd, and load/attach data
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
# Create/attach training and test subset as demonstrated in text
# Load libraries, set wd, and load/attach data
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
# Create/attach training and test subset as demonstrated in text
final$gp <- runif(dim(final)[1])
test <- subset(final, final$gp <= 0.1)
train <- subset(final, final$gp > 0.1)
attach(train)
attach(test)
# Remove columns used for creating subsets
train["gp"] <- NULL
test["gp"] <- NULL
# Fit linear regression with all features
fit <- lm(ssc ~ age + gender + location + ethnicity + coder + som1 + som2 + som3 + som4
+ som5 + som6 + som7 + som8 + som9 + som10 + som11 + som12 + som13 + som14)
summary(fit)
step <- stepAIC(fit, direction = "both")
step
step$anova
rm(step)
rm(fit)
# Build model with only retained variables
fit1 <- lm( ssc ~ age + location + ethnicity + coder + som1 + som2 + som3 +
som4 + som5 + som10 + som11 + som12 + som13 + som14)
summary(fit1)
# Remove training set (no longer needed)
detach(train)
rm(train)
# Now predict using the test set
test$ssc_pred <- predict(fit1, newdata = test)
rm(fit1)
#See how predicted ssc compares to actual ssc values
library(ggplot2)
ggplot(data = test, aes(x = ssc_pred, y = ssc)) +
geom_point(color = "red") +
geom_line(aes(x = ssc, y = ssc), color = "blue")
# Load libraries, set wd, and load/attach data
library(MASS)
# Load libraries, set wd, and load/attach data
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
# Load libraries, set wd, and load/attach data
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
# Load libraries, set wd, and load/attach data
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
# Load libraries, set wd, and load/attach data
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
attach(final)
# Create/attach training and test subset as demonstrated in text
final$gp <- runif(dim(final)[1])
test <- subset(final, final$gp <= 0.1)
train <- subset(final, final$gp > 0.1)
attach(train)
attach(test)
# Load libraries, set wd, and load/attach data
library(MASS)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("fdata.rdata")
# Create/attach training and test subset as demonstrated in text
final$gp <- runif(dim(final)[1])
test <- subset(final, final$gp <= 0.1)
train <- subset(final, final$gp > 0.1)
attach(train)
# Remove columns used for creating subsets
train["gp"] <- NULL
test["gp"] <- NULL
# Fit linear regression with all features
fit <- lm(ssc ~ age + gender + location + ethnicity + coder + som1 + som2 + som3 + som4
+ som5 + som6 + som7 + som8 + som9 + som10 + som11 + som12 + som13 + som14)
summary(fit)
step <- stepAIC(fit, direction = "both")
step
step$anova
rm(step)
rm(fit)
# Build model with only retained variables
fit1 <- lm( ssc ~ age + location + ethnicity + coder + som1 + som2 + som3 +
som4 + som5 + som10 + som11 + som12 + som13 + som14)
summary(fit1)
# Remove training set (no longer needed)
detach(train)
rm(train)
# Now predict using the test set
test$ssc_pred <- predict(fit1, newdata = test)
rm(fit1)
#See how predicted ssc compares to actual ssc values
library(ggplot2)
ggplot(data = test, aes(x = ssc_pred, y = ssc)) +
geom_point(color = "red") +
geom_line(aes(x = ssc, y = ssc), color = "blue")
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("NatalRiskData.rData")
train <- sdata[sdata$ORIGRANDGROUP<=5,]
test <- sdata[sdata$ORIGRANDGROUP>5,]
complications <- c("ULD_MECO","ULD_PRECIP","ULD_BREECH")
riskfactors <- c("URF_DIAB", "URF_CHYPER", "URF_PHYPER",
"URF_ECLAM")
y <- "atRisk"
x <- c("PWGT",
"UPREVIS",
"CIG_REC",
"GESTREC3",
"DPLURAL",
complications,
riskfactors)
fmla <- paste(y, paste(x, collapse="+"), sep="~")
print(fmla)
model <- glm(fmla, data=train, family=binomial(link="logit"))
train$pred <- predict(model, newdata=train, type="response")
test$pred <- predict(model, newdata=test, type="response")
library(ggplot2)
ggplot(train, aes(x=pred, color=atRisk, linetype=atRisk)) +
geom_density()
#Use threshold for test set prediction and get confusion matrix
confusion.test <- table(pred=test$pred>0.5, target = test$target)
confusion.test <- table(pred=test$pred>0.02, target = test$target)
confusion.test <- table(pred=test$pred>0.02, target = test$atRisk)
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
load("NatalRiskData.rData")
train <- sdata[sdata$ORIGRANDGROUP<=5,]
test <- sdata[sdata$ORIGRANDGROUP>5,]
complications <- c("ULD_MECO","ULD_PRECIP","ULD_BREECH")
riskfactors <- c("URF_DIAB", "URF_CHYPER", "URF_PHYPER",
"URF_ECLAM")
y <- "atRisk"
x <- c("PWGT",
"UPREVIS",
"CIG_REC",
"GESTREC3",
"DPLURAL",
complications,
riskfactors)
fmla <- paste(y, paste(x, collapse="+"), sep="~")
print(fmla)
model <- glm(fmla, data=train, family=binomial(link="logit"))
train$pred <- predict(model, newdata=train, type="response")
test$pred <- predict(model, newdata=test, type="response")
library(ggplot2)
ggplot(train, aes(x=pred, color=atRisk, linetype=atRisk)) +
geom_density()
#Use threshold for test set prediction and get confusion matrix
confusion.test <- table(pred=test$pred>0.02, target = test$atRisk)
confusion.test
#rows contain predicted negative and positives
#columns contain actual negatives and positives
#Then calculate, accuracy, precision and recall
accuracy <- (confusion.test[2,2] + confusion.test[1,1])/sum(confusion.test[,])
accuracy
precision <- confusion.test[2,2] / sum(confusion.test[2,])
precision
recall <- confusion.test[2,2] / sum(confusion.test[,2])
recall
#Web Interactive Data Science with Shiny
#http://shiny.rstudio.com/gallery/
setwd("C:\\Users\\Kyle\\Dropbox\\CS\\CS3654\\R\\Inclass9")
install.packages("shiny")
library(shiny)
library(shiny)
#have your ui.R and server.R files in the "App-1" folder
#in your working directory
#Save this Shiny.R file in the working directory
#Run your app by:
runApp("App-1")
runApp("App-1")
